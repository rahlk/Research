# SEER: Heterogeneous Defect Prediction using *Causal Inference Learning*

#### Methodology
  
Key challenge is to pick the right metrics from source that match the target. 
  
  - SEER hypothesizes that the best source metrics are the ones that have the highest (i.e., most causal) relationship with a target metric.
      
  - In other words, it is not unfair to assume that (Target_Metrics -> Target_defects). Therefore, we can assume atleast empirically that if (Source_metric -> Target_Metric), then that Source_metric can latently predict for Target_defects (Source_metrics ~~> Target_defects). *Note: -> denotes causes*
  
  1. For every target metric, we run a "Causal Inference Learner" to a source metric that has the highest causal relationship. This leads to three subcases:
 
    a. We find no source metric. In this case, ignore the metric from the target set.
    
    b. We find multiple matches. In this case, pick the highest $\delta_HSIC$. Larger the difference, stronger the causation.
    
    c. We find reverse relations, i.e., Target Metric -> Source Metric. Again, we're not interested, so ignore.
 
  2. Ensure only metric pairs that have strong uni-directional causal relations are chosen in both target and source. For example, between Apache Poi (20 metrics) and JDT (66 metrics) we found 14 with very strong causal relations. We use only those 14 to build a model.
  
  3. Also, very imp. to ensure that causality between metrics is not a one-off event, we run a bootstrapping on the metrics with 20 repeats and pick them only if the median is statistically significant (need to find a better way to do this).
  
#### Benefits over other HDPs

- Metric matching subsumes feature selection/weighting.
- Agnostic to heterogeneous/homogeneous transfer learning.
- Way more matches compared to JC Nam's KSAnalyser+Weighted Bipartite Matching. And works better. See [result]().
- There seem to latent causal effects that were ignored by other methods.
- Works better than TCA+. See [result]().
- Also, we find more bellwethers. See [result]().

#### *Causal Inference Learning*
![seer](https://cloud.githubusercontent.com/assets/1433964/19671976/ce655450-9a40-11e6-9525-56a2a271547b.jpg)

 
